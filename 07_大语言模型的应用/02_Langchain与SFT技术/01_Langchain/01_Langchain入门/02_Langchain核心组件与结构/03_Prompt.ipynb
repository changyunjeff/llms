{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5929d5ca-9500-48f8-bb18-ca35f27c61b6",
   "metadata": {},
   "source": [
    "# 3 Prompts（提示工程）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24eaec3-2f91-4a3c-bb8d-e0bd877fdc2c",
   "metadata": {},
   "source": [
    "在 LangChain 框架中，**Prompts（提示工程）** 是连接用户意图与语言模型（LLM）的核心桥梁。它通过结构化的输入模板，精准引导模型生成符合预期的输出。与直接向 LLM 输入原始文本相比，精心设计的提示能显著提升模型性能 —— 这也是为什么 LangChain 将 Prompts 作为独立核心模块的原因。\n",
    "\n",
    "Prompts 模块是 LangChain 中连接用户与模型的 \"翻译官\"，通过结构化模板将模糊需求转化为模型可理解的指令。核心要点：\n",
    "\n",
    "- 根据模型类型选择PromptTemplate（文本模型）或ChatPromptTemplate（聊天模型）；\n",
    "\n",
    "- 利用变量替换、部分绑定、格式约束等功能提升提示灵活性；\n",
    "\n",
    "- 复杂场景通过提示组合实现模块化管理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd419f39-818a-40f7-8170-c2043883a3b9",
   "metadata": {},
   "source": [
    "## 一、Prompts 的核心价值：为什么需要提示工程？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fc9e7-b795-404e-aaa2-f2cc84b4b460",
   "metadata": {},
   "source": [
    "语言模型本身是 \"通用型\" 的，需要通过提示来约束其行为。例如：\n",
    "\n",
    "- 同样问 \"介绍 LangChain\"，提示 \"用 300 字学术风格\" 和 \"用 3 句话通俗解释\" 会得到完全不同的结果；\n",
    "\n",
    "- 缺乏格式约束时，模型可能返回杂乱的文本，而提示 \"以 JSON 格式输出关键词\" 能直接得到结构化数据。\n",
    "\n",
    "LangChain 的 Prompts 模块解决了三大问题：\n",
    "\n",
    "1. **标准化输入**：通过模板固定提示结构，避免重复编写相同指令；\n",
    "\n",
    "2. **动态变量替换**：支持在模板中插入变量（如用户输入、上下文信息）；\n",
    "\n",
    "3. **多模态适配**：针对不同类型模型（文本模型 / 聊天模型）提供专用模板。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb0195-261b-4c4e-9e40-e0565fdca726",
   "metadata": {},
   "source": [
    "## 二、Prompts 核心组件与类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebda144-fdf3-4754-80b4-35948458535f",
   "metadata": {},
   "source": [
    "LangChain 官网明确将 Prompt Templates 分为三类：`String PromptTemplates`（单字符串模板）、`ChatPromptTemplates`（多消息模板）、`MessagesPlaceholder`（消息列表占位符）。以下按官网示例逐一讲解，确保代码零错误。\n",
    "\n",
    "|提示类型|\t适用模型|\t核心特点|\n",
    "|--|--|--|\n",
    "|`String PromptTemplates`|\t用于生成单一字符串的模板|\t输入是 “变量字典”，输出是`PromptValue`对象（可转字符串）。|\n",
    "|`ChatPromptTemplates`|用于生成多轮消息列表的模板，适配「聊天模型」（如 GPT-3.5/4、Claude）|输入是 “变量字典”，输出是含多角色消息的PromptValue对象（可转BaseMessage列表）|\n",
    "|`MessagesPlaceholder`|用于在 ChatPromptTemplate 中插入动态消息列表（如对话历史、外部消息记录），解决 “固定模板 + 动态多轮消息” 的组合问题。|多轮对话中，将历史消息（人类 + AI）嵌入到固定模板中，避免手动拼接消息列表|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8223df-dccf-40e5-afbe-98da90cde749",
   "metadata": {},
   "source": [
    "## 三、实践案例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478712c-0573-479e-a889-8124ab3af895",
   "metadata": {},
   "source": [
    "### 案例1：单字符串模板（String PromptTemplates）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f347804-ef9e-4419-85cd-d512df91e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PromptValue对象信息 ===\n",
      "类型：<class 'langchain_core.prompt_values.StringPromptValue'>\n",
      "转字符串（给纯文本模型）：\n",
      "请用3句话解释LangChain的PromptTemplate, 目标读者是Python初学者\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 创建字符串模板（两种方式）\n",
    "# 方式1：直接指定模板字符串（推荐，代码更简单）\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "请用3句话解释{concept}, 目标读者是{audience}\n",
    "\"\"\")\n",
    "\n",
    "# 方式2：显示指定 input_variables\n",
    "# prompt_template = PromptTemplate(\n",
    "#     template=\"请用3句话解释{concept}, 目标读者是{audience}\",\n",
    "#     input_variables=[\"concept\", \"audience\"] # 必须与模板变量名完全一致\n",
    "# )\n",
    "\n",
    "# 2. 传入变量生成PromptValue\n",
    "prompt_value = prompt_template.invoke({\n",
    "    \"concept\": \"LangChain的PromptTemplate\",\n",
    "    \"audience\": \"Python初学者\"\n",
    "})\n",
    "\n",
    "# 3. 适配不同的模型：转为字符串（给纯文本模型）或查看原始PromptValue\n",
    "print(\"=== PromptValue对象信息 ===\")\n",
    "print(f\"类型：{type(prompt_value)}\")\n",
    "print(f\"转字符串（给纯文本模型）：{prompt_value.to_string()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a510f77-b181-494e-8eaf-1b51dad3a5ad",
   "metadata": {},
   "source": [
    "### 案例2：多消息模板（ChatPromptTemplates）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fc667bb-2a3c-4cba-82c8-a4989391eddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "角色：system，内容：你是'Python 编程'领域的专业助手，你负责提供准确且精要的专业描述，回答不超过200字。\n",
      "角色：human，内容：我的问题是：LangChain的ChatPromptTemplate和PromptTemplate有什么区别？\n",
      "在LangChain中，ChatPromptTemplate用于生成对话式文本，而PromptTemplate则用于生成非对话式文本。ChatPromptTemplate更适合用于生成对话流程，包含用户和系统之间的交互，而PromptTemplate更适合用于生成单一文本。因此，区别主要在于用途和生成文本的形式。"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    # 角色1：system ———— 定义模型身份\n",
    "    {\"role\":\"system\", \"content\":\"你是'{domain}'领域的专业助手，你负责提供准确且精要的专业描述，回答不超过200字。\"},\n",
    "    # 角色2：user ———— 用户动态输入\n",
    "    {\"role\":\"human\", \"content\":\"我的问题是：{question}\"},\n",
    "])\n",
    "\n",
    "# 传入变量生成PromptValue\n",
    "prompt_value = chat_prompt_template.invoke({\n",
    "    \"domain\": \"Python 编程\",\n",
    "    \"question\": \"LangChain的ChatPromptTemplate和PromptTemplate有什么区别？\",\n",
    "})\n",
    "\n",
    "messages = prompt_value.to_messages()\n",
    "for msg in messages:\n",
    "    print(f\"角色：{msg.type}，内容：{msg.content}\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"UIUIAPI_API_KEY\"),\n",
    "    base_url=os.getenv(\"UIUIAPI_BASE_URL\"),\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.8,\n",
    ")\n",
    "for chunk in llm.stream(messages):\n",
    "    for ch in chunk.content:\n",
    "        print(ch, end='', flush=True)\n",
    "        time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006fabc-843c-481e-94fb-b0ce3fb99488",
   "metadata": {},
   "source": [
    "### 案例3：消息列表占位符(MessagesPlaceholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f899a3d1-81b2-4cd6-b02d-a3eb8c49b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 最终消息列表（系统消息+历史对话） ===\n",
      "1. 角色：system，内容：你是记忆助手，会基于历史对话回答新问题，不会编造信息。\n",
      "2. 角色：human，内容：LangChain是什么？\n",
      "3. 角色：ai，内容：LangChain是构建LLM应用的框架，核心是组件化和可组合性。\n",
      "4. 角色：human，内容：它的核心模块有哪些？\n",
      "LangChain的核心模块包括语言处理模块、链式编程模块和应用适配模块。语言处理模块负责处理自然语言输入和输出，链式编程模块负责实现链式调用的编程风格，应用适配模块负责将LangChain框架与具体应用场景进行适配。这些模块共同工作，构建了LangChain的整体架构。"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 创建含占位符的聊天模板\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    # 固定消息\n",
    "    {\"role\":\"system\", \"content\": \"你是记忆助手，会基于历史对话回答新问题，不会编造信息。\"},\n",
    "    # 动态消息占位符：外部传入的消息列表将插入到这里\n",
    "    MessagesPlaceholder(variable_name=\"msgs\")\n",
    "])\n",
    "\n",
    "# 2. 准备外部消息列表（如对话历史）——官网示例格式\n",
    "conversation_history = [\n",
    "    HumanMessage(content=\"LangChain是什么？\"),\n",
    "    AIMessage(content=\"LangChain是构建LLM应用的框架，核心是组件化和可组合性。\"),\n",
    "    HumanMessage(content=\"它的核心模块有哪些？\")  # 最新问题\n",
    "]\n",
    "\n",
    "prompt_value = chat_prompt_template.invoke({\n",
    "    \"msgs\": conversation_history\n",
    "})\n",
    "\n",
    "# 查看最终消息列表（固定系统消息 + 动态历史消息）\n",
    "print(\"=== 最终消息列表（系统消息+历史对话） ===\")\n",
    "messages = prompt_value.to_messages()\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"{i}. 角色：{msg.type}，内容：{msg.content}\")\n",
    "\n",
    "for chunk in llm.stream(messages):\n",
    "    for char in chunk.content:\n",
    "        print(char, end='', flush=True)\n",
    "        time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7241943-1fd6-4cd7-b14e-acb5de310823",
   "metadata": {},
   "source": [
    "**官网更推荐的写法：避免导入MessagesPlaceholder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b164ec7-93a6-4e20-99c1-dc8f457dae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 最终消息列表（系统消息+历史对话） ===\n",
      "1. 角色：system，内容：你是记忆助手，会基于历史对话回答新问题，不会编造信息。\n",
      "2. 角色：human，内容：LangChain是什么？\n",
      "3. 角色：ai，内容：LangChain是构建LLM应用的框架，核心是组件化和可组合性。\n",
      "4. 角色：human，内容：它的核心模块有哪些？\n",
      "LangChain的核心模块包括：\n",
      "\n",
      "1. 语言模块：处理自然语言理解和生成\n",
      "2. 知识模块：管理知识图谱和相关知识库\n",
      "3. 编程模块：支持编写和执行LLM应用的代码\n",
      "4. 控制模块：管理应用的流程和交互逻辑\n",
      "5. 学习模块：支持模型的在线学习和优化"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    {\"role\":\"system\", \"content\": \"你是记忆助手，会基于历史对话回答新问题，不会编造信息。\"},\n",
    "    {\"role\":\"placeholder\", \"content\": \"{msgs}\"}\n",
    "])\n",
    "\n",
    "conversation_history = [\n",
    "    HumanMessage(content=\"LangChain是什么？\"),\n",
    "    AIMessage(content=\"LangChain是构建LLM应用的框架，核心是组件化和可组合性。\"),\n",
    "    HumanMessage(content=\"它的核心模块有哪些？\")  # 最新问题\n",
    "]\n",
    "\n",
    "prompt_value = chat_prompt_template.invoke({\n",
    "    \"msgs\": conversation_history\n",
    "})\n",
    "\n",
    "# 查看最终消息列表（固定系统消息 + 动态历史消息）\n",
    "print(\"=== 最终消息列表（系统消息+历史对话） ===\")\n",
    "messages = prompt_value.to_messages()\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"{i}. 角色：{msg.type}，内容：{msg.content}\")\n",
    "\n",
    "for chunk in llm.stream(messages):\n",
    "    for char in chunk.content:\n",
    "        print(char, end='', flush=True)\n",
    "        time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c17732-2467-4f44-b727-6103c61cf50e",
   "metadata": {},
   "source": [
    "## 四、提示工程最佳实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74c56e-a95e-48a0-8701-9786ffb2b999",
   "metadata": {},
   "source": [
    "1. **明确角色与任务**：在系统消息中清晰定义模型角色（如：你是数据分析师）和任务目标\n",
    "\n",
    "2. **提供示例（少样本提示）**：复杂任务时加入示例（如“输出格式如下：示例1 ...”）\n",
    "\n",
    "3. **控制输出长度**：明确约束（如“不超过3句话”），避免模型输出过长或过短\n",
    "\n",
    "4. **使用分隔符**：用、===等分隔不同内容\n",
    "\n",
    "5. **逐步优化**：根据输出不断重新调整提示词（如补充：“不要使用专业术语”）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b1621-214a-4cac-a2e7-905f5d5e814e",
   "metadata": {},
   "source": [
    "## 五、常见问题与解决方案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb9be7-34fb-4873-a1ef-38455d83313d",
   "metadata": {},
   "source": [
    "|问题|\t解决方案|\n",
    "|--|--|\n",
    "|模型输出格式混乱|\t用JsonOutputParser强制格式，或在提示中加入示例|\n",
    "|模型忽略部分指令|\t关键要求放在提示开头，或用加粗（**）强调|\n",
    "|提示过长超出 Token 限制|\t拆分提示为子模板，或使用partial()绑定固定内容|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a572f-b789-45be-887d-e66b74375c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
